The purpose of this project is to develop an AI-powered program capable of harvesting data from a website. Harvesting is a technique I learned at Marymount University, where we extract and organize valuable information from web sources. What is different about this project is the implementation of Artificial Intelligence (AI) to enhance data processing, analysis, and text summarization. By integrating AI models such as OpenAI's GPT3.5, this program not only extracts numerical and textual data, but also analyzes, summarizes and interprets the collected information.

I faced a few obstacles in making my program fully functional. I encountered a few issues, which were simple and advanced. For example, I experienced some spelling and misplacing mistakes within the program that caused syntax and other issues. In addition, there were issues with accessing the PDF file and web page to harvest data. On the other hand, there is one issue I cannot control unless I pay for a subscription to OpenAI, as there is a limitation where the output states that I have exceeded my limit. Despite the complication with integrating AI, I researched solutions and fixed my code to make it functional, such as following tweaking recommendations. As for AI, there are many AI modules out there. Although, I have used the one I am familiar with for this program.

This project is a combination of both AI and non-AI elements to demonstrate that my program works despite the AI limitations. I applied everything I learned from the Python course at Marymount University, such as lists, variables, etc., while also implementing AI and new modules like BeautifulSoup and pdfplumber for this project. I learned how to harvest data from a website with AI, though the limitation for multiple attempts is an unfortunate challenge in making program work.
